{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Banner.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **IA Biom√©dica:** Laboratorio PharmaNet: Modelo, entrenamiento e inferencia \n",
    "\n",
    "\n",
    "> ##### Descubrimiento de Farmacos\n",
    "\n",
    "\n",
    "> **Instructores**\n",
    "\n",
    "*  Julio Castellanos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Pr√°ctica: An√°lisis y Comprensi√≥n de PharmaNet\n",
    "\n",
    "Esta pr√°ctica se enfoca en revisar dos scripts fundamentales:\n",
    "\n",
    "- El c√≥digo de entrenamiento, donde se definen las rutinas para cargar datos, entrenar y evaluar el modelo con m√©tricas como Accuracy, NAP y AUC.\n",
    "- El c√≥digo de inferencia, que demuestra c√≥mo aplicar el modelo para obtener predicciones con mol√©culas de test.\n",
    "\n",
    "La meta principal es entender paso a paso c√≥mo funciona PharmaNet al transformar SMILES en tensores, procesarlos mediante su arquitectura (Conv + RNN) y generar probabilidades de afinidad para cada target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PharmaNet Tutorial: Entrenamiento e Inferencia\n",
    "\n",
    "Este *Notebook* ilustra los pasos fundamentales para:\n",
    "1. Entrenar el modelo **PharmaNet** usando datos de SMILES.\n",
    "2. Realizar  inferencia sobre un conjunto de prueba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports Principales para Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliocesar/miniforge3/envs/PharmaNet/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.9.0.post2\n"
     ]
    }
   ],
   "source": [
    "# ## 1. Importaciones Principales\n",
    "\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Modulos propios (aseg√∫rate de tener estas rutas en tu proyecto)\n",
    "from data.data_loader import SMILESDataset\n",
    "from utils.metrics import pltauc, norm_ap_optimized\n",
    "from models.Model import Model\n",
    "\n",
    "\n",
    "print(\"PyTorch Version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuraci√≥n de Par√°metros y Semilla\n",
    "\n",
    "En esta secci√≥n, definimos los par√°metros necesarios para la ejecuci√≥n:\n",
    "- GPU o CPU\n",
    "- Fijaci√≥n de semilla aleatoria para reproducibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo seleccionado: cpu\n"
     ]
    }
   ],
   "source": [
    "# 2. Configuraci√≥n de Par√°metros y Semilla\n",
    "\n",
    "seed = 6766\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Configurar GPU (si est√° disponible)\n",
    "ngpu = 1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '{}'.format(ngpu)\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "print(\"Dispositivo seleccionado:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lectura de Datos y Cross-Validation\n",
    "\n",
    "Aqu√≠ cargamos archivos CSV con SMILES (por ejemplo, `Smiles_1.csv`, `Smiles_2.csv`, etc.) y seleccionamos la parte de entrenamiento y prueba seg√∫n un √≠ndice de `cross_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for train: 15321\n",
      "Data for test : 5259\n"
     ]
    }
   ],
   "source": [
    "# 3. Lectura de Datos\n",
    "train_path = \"data/datasets/DUDE/\"\n",
    "A = pd.read_csv(train_path + 'Smiles_1.csv')\n",
    "B = pd.read_csv(train_path + 'Smiles_2.csv')\n",
    "C = pd.read_csv(train_path + 'Smiles_3.csv')\n",
    "D = pd.read_csv(train_path + 'Smiles_4.csv')\n",
    "\n",
    "cross_val = 1\n",
    "\n",
    "if cross_val == 1:\n",
    "    data_train = pd.concat([A, B, C], ignore_index=True)\n",
    "    data_test = D\n",
    "elif cross_val == 2:\n",
    "    data_train = pd.concat([A, C, D], ignore_index=True)\n",
    "    data_test = B\n",
    "elif cross_val == 3:\n",
    "    data_train = pd.concat([A, B, D], ignore_index=True)\n",
    "    data_test = C\n",
    "else:\n",
    "    data_train = pd.concat([B, C, D], ignore_index=True)\n",
    "    data_test = A\n",
    "\n",
    "print('Data for train:', len(data_train['Smiles']))\n",
    "print('Data for test :', len(data_test['Smiles']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Target</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC[C@H](Cc1cccc(F)c1)NC(=O)c4cc(Br)c(c2ccnc3[n...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cc4n[nH]c5ccc(c3cncc(OC[C@@H](N)Cc1c[nH]c2cccc...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N[C@H](COc4cncc(c3ccc2NC(=O)C(c1ccco1)c2c3)c4)...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(C)(Cc1ccco1)C5C(=O)Nc6ccc(c4cncc(OC[C@@H](N...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCn3c(c1nonc1N)nc4c(C#CC(C)(C)O)nc(O[C@@H](CCN...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15316</th>\n",
       "      <td>COc1ccc(F)cc1C(C)(C)CC(O)(Cc2cc(C)cc(C)c2)C(F)...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15317</th>\n",
       "      <td>OC(=O)c5ccc4C3=NN(c1ccc(C#N)c(Cl)c1)[C@H](c2cc...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15318</th>\n",
       "      <td>COc1ccc(F)cc1C(C)(C)CC(O)(Cc2cc(C)cc(C)c2C#N)C...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15319</th>\n",
       "      <td>COc4c(O)ccc5o\\c(=C/c1cccc(O)c1)c3C2C(NC(C)(C)C...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15320</th>\n",
       "      <td>CC(Cc1c[nH]c2ccccc12)NS(=O)(=O)c3c(C)cc(C)cc3C</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15321 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Smiles Target  Label\n",
       "0      NC[C@H](Cc1cccc(F)c1)NC(=O)c4cc(Br)c(c2ccnc3[n...   akt1      0\n",
       "1      Cc4n[nH]c5ccc(c3cncc(OC[C@@H](N)Cc1c[nH]c2cccc...   akt1      0\n",
       "2      N[C@H](COc4cncc(c3ccc2NC(=O)C(c1ccco1)c2c3)c4)...   akt1      0\n",
       "3      CC(C)(Cc1ccco1)C5C(=O)Nc6ccc(c4cncc(OC[C@@H](N...   akt1      0\n",
       "4      CCn3c(c1nonc1N)nc4c(C#CC(C)(C)O)nc(O[C@@H](CCN...   akt1      0\n",
       "...                                                  ...    ...    ...\n",
       "15316  COc1ccc(F)cc1C(C)(C)CC(O)(Cc2cc(C)cc(C)c2)C(F)...    mcr    101\n",
       "15317  OC(=O)c5ccc4C3=NN(c1ccc(C#N)c(Cl)c1)[C@H](c2cc...    mcr    101\n",
       "15318  COc1ccc(F)cc1C(C)(C)CC(O)(Cc2cc(C)cc(C)c2C#N)C...    mcr    101\n",
       "15319  COc4c(O)ccc5o\\c(=C/c1cccc(O)c1)c3C2C(NC(C)(C)C...    mcr    101\n",
       "15320     CC(Cc1c[nH]c2ccccc12)NS(=O)(=O)c3c(C)cc(C)cc3C    mcr    101\n",
       "\n",
       "[15321 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Target</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C/C(c1ccc[nH]1)=c2/c(=O)[nH]c3ccc(NC(N)=O)cc23</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cc3n[nH]c4cn(=O)c(c2cncc(OC[C@@H](N)Cc1ccccc1)...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C5CN(Cc4ccc(c2nc1ncccc1cc2c3ccccc3)cc4)CCC5c7c...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N[C@H](COc4cncc(c3ccc2cnc(c1ccncc1)cc2c3)c4)Cc...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cc4n[nH]c5ccc(c3cncc(OC[C@@H](N)Cc2cccc(c1cccc...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>Clc4cccc(C3CCN(c1[nH]c(=O)[nH]c(=O)c1Cc2ccccc2...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>CC1(C)CCC[C@@]4(C)[C@@H]1Nc3cc2nc(O)cc(C(F)(F)...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5256</th>\n",
       "      <td>CC#C[C@]5(O)CC[C@H]4[C@@H]2CCC1=CC(=O)CCC1=C2[...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>COc1ccc(F)cc1C(C)(C)CC(O)(Cn2cc(C)nc2C)C(F)(F)F</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5258</th>\n",
       "      <td>CC4=CC(C)(C)Nc5ccc3c1cc(F)ccc1oc(=C2SCCCS2)c3c45</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5259 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Smiles Target  Label\n",
       "0        C/C(c1ccc[nH]1)=c2/c(=O)[nH]c3ccc(NC(N)=O)cc23   akt1      0\n",
       "1     Cc3n[nH]c4cn(=O)c(c2cncc(OC[C@@H](N)Cc1ccccc1)...   akt1      0\n",
       "2     C5CN(Cc4ccc(c2nc1ncccc1cc2c3ccccc3)cc4)CCC5c7c...   akt1      0\n",
       "3     N[C@H](COc4cncc(c3ccc2cnc(c1ccncc1)cc2c3)c4)Cc...   akt1      0\n",
       "4     Cc4n[nH]c5ccc(c3cncc(OC[C@@H](N)Cc2cccc(c1cccc...   akt1      0\n",
       "...                                                 ...    ...    ...\n",
       "5254  Clc4cccc(C3CCN(c1[nH]c(=O)[nH]c(=O)c1Cc2ccccc2...    mcr    101\n",
       "5255  CC1(C)CCC[C@@]4(C)[C@@H]1Nc3cc2nc(O)cc(C(F)(F)...    mcr    101\n",
       "5256  CC#C[C@]5(O)CC[C@H]4[C@@H]2CCC1=CC(=O)CCC1=C2[...    mcr    101\n",
       "5257    COc1ccc(F)cc1C(C)(C)CC(O)(Cn2cc(C)nc2C)C(F)(F)F    mcr    101\n",
       "5258   CC4=CC(C)(C)Nc5ccc3c1cc(F)ccc1oc(=C2SCCCS2)c3c45    mcr    101\n",
       "\n",
       "[5259 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparaci√≥n del Vocabulario (charset) y Definici√≥n de Longitud M√°xima\n",
    "Extraemos un conjunto de caracteres √∫nicos usados en los SMILES y calculamos la longitud m√°xima de la secuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteres √∫nicos: {'(', '1', 'o', '#', 'B', 'i', 'r', 'n', ']', '-', 'O', '\\\\', '=', '+', 'c', ')', 'l', 'C', 's', '7', '9', '8', '@', 'N', '5', 'S', 'H', 'P', '2', 'F', '[', '3', '/', 'I', '6', '4'}\n",
      "Total de caracteres: 36\n",
      "Max. longitud de SMILE: 116\n"
     ]
    }
   ],
   "source": [
    "# 4. Vocabulario y Embedding\n",
    "charset = set(\"\".join(list(data_train.Smiles)) + \"\".join(list(data_test.Smiles)))\n",
    "vocab_size = len(charset)\n",
    "char_to_int = dict((c, i) for i, c in enumerate(charset))\n",
    "\n",
    "embed_tr = max([len(smile) for smile in data_train.Smiles])\n",
    "embed_te = max([len(smile) for smile in data_test.Smiles])\n",
    "embed = max(embed_tr, embed_te)\n",
    "\n",
    "print('Caracteres √∫nicos:', str(charset))\n",
    "print('Total de caracteres:', vocab_size)\n",
    "print('Max. longitud de SMILE:', embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Construcci√≥n del Modelo (PharmaNet)\n",
    "\n",
    "Se instancia la clase `Model(...)` que define la arquitectura Conv + RNN.  \n",
    "Luego se imprime el modelo para revisar su estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "Model(\n",
      "  (module_mol): ModuleList(\n",
      "    (0): Conv2d(36, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(3, 2))\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): GRU(128, 256, num_layers=10, batch_first=True, bidirectional=True)\n",
      "    (5): Upsample(size=64, mode=nearest)\n",
      "  )\n",
      "  (fc1): Linear(in_features=512, out_features=102, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Construcci√≥n del Modelo\n",
    "num_classes = max(data_train.Label) + 1\n",
    "print(num_classes)\n",
    "hidden_size = 256\n",
    "kernel_size = 5\n",
    "\n",
    "bidireccional = True\n",
    "num_layers = 10\n",
    "\n",
    "net = Model(vocab_size,\n",
    "            num_classes,\n",
    "            hidden_size,\n",
    "            bidireccional,\n",
    "            num_layers,\n",
    "            kernel_size\n",
    "            ).to(device)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Definici√≥n del Optimizador y la Funci√≥n de P√©rdida\n",
    "\n",
    "Usamos Adam como optimizador y BCELoss (aplicando `sigmoid` en cada clase).  \n",
    "El scheduler reduce el learning rate si no hay mejoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Optimizador y P√©rdida\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=7)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Creaci√≥n de los DataLoaders (Train/Test)\n",
    "\n",
    "Se definen:\n",
    "- El dataset con la clase `SMILESDataset`.\n",
    "- DataLoader con sampler balanceado o shuffle, seg√∫n los argumentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader y test loader creados.\n"
     ]
    }
   ],
   "source": [
    "# 7. DataLoaders\n",
    "\n",
    "neighbours = 0\n",
    "padding = False\n",
    "\n",
    "batch_size = 128\n",
    "workers = 4\n",
    "\n",
    "train_datasets = SMILESDataset(data_train, vocab_size, char_to_int, embed, neighbours, padding)\n",
    "test_datasets  = SMILESDataset(data_test, vocab_size, char_to_int, embed, neighbours, padding)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_datasets, batch_size=batch_size, drop_last=True, shuffle=True, num_workers=workers)\n",
    "test_loader  = DataLoader(test_datasets,  batch_size=batch_size, drop_last=True, shuffle=True, num_workers=workers)\n",
    "\n",
    "print(\"Train loader y test loader creados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Funciones de Entrenamiento y Evaluaci√≥n\n",
    "\n",
    "- **train(epoch)**: Modo `train()`, calcula p√©rdida y backprop.\n",
    "- **evaluate(epoch)**: Modo `eval()`, sin backprop, y se calculan m√©tricas finales (NAP, AUC, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    # Coloca el modelo en modo entrenamiento (permite dropout, actualiza gradientes)\n",
    "    net.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    lab = np.array([])                       # Para almacenar etiquetas reales\n",
    "    maps = np.empty((0, num_classes))        # Para almacenar predicciones (probabilidades)\n",
    "\n",
    "    # Iteramos sobre cada batch (inputs, _, labels) proveniente de train_loader\n",
    "    for inputs, _, labels in tqdm(train_loader):\n",
    "        # Convertimos a tensores en float32 y los movemos al dispositivo (CPU/GPU)\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Reiniciamos gradientes antes de cada batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Activamos el c√°lculo de gradientes\n",
    "        with torch.set_grad_enabled(True):\n",
    "            # Forward pass: obtenemos outputs de la red\n",
    "            outputs = net(inputs)\n",
    "            loss = 0\n",
    "\n",
    "            # Para cada clase, calculamos el aporte a la p√©rdida usando BCELoss\n",
    "            for i in range(num_classes):\n",
    "                labe = labels.clone()\n",
    "                labe[labels == i] = 1\n",
    "                labe[labels != i] = 0\n",
    "                loss += criterion(F.sigmoid(outputs[:, i].float()), labe.float().to(device))\n",
    "\n",
    "            # Convertimos outputs a numpy para calcular m√©tricas (softmax de outputs)\n",
    "            outputs_array = F.softmax(outputs.clone().detach().cpu(), dim=1).numpy()\n",
    "            maps = np.append(maps, outputs_array, axis=0)\n",
    "\n",
    "            # Guardamos las etiquetas en un array para m√©tricas\n",
    "            labels_array = labels.clone().cpu().detach().numpy()\n",
    "            lab = np.append(lab, labels_array)\n",
    "\n",
    "            # Obtenemos la predicci√≥n (clase con mayor probabilidad)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Backprop: calculamos gradientes y actualizamos pesos\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Acumulamos p√©rdida total del batch\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Calculamos aciertos para accuracy\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    # P√©rdida media en la √©poca\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    # Precisi√≥n en la √©poca\n",
    "    epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "    # C√°lculo de m√©tricas: NAP y AUC (incluye macro y micro)\n",
    "    epoch_nap, epoch_f = norm_ap_optimized(maps, lab, num_classes)\n",
    "    epoch_auc = pltauc(maps, lab, num_classes)\n",
    "\n",
    "    # Imprimimos m√©tricas clave\n",
    "    print('Phase Train, Loss: {:.4f} Acc: {:.4f} NAP: {:.4f} F-measure: {:.4f} AUC: {:.4f}'.format(\n",
    "        epoch_loss, epoch_acc, epoch_nap[-1], epoch_f[-1], epoch_auc[\"micro\"]))\n",
    "\n",
    "    # Retornamos valores relevantes para graficar o almacenar\n",
    "    return epoch_loss, epoch_acc, epoch_nap[-1], epoch_f[-1], epoch_auc[\"micro\"]\n",
    "\n",
    "\n",
    "def evaluate(epoch):\n",
    "    # Coloca el modelo en modo evaluaci√≥n (desactiva dropout, no requiere gradientes)\n",
    "    net.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    lab = np.array([])                       # Etiquetas reales\n",
    "    maps = np.empty((0, num_classes))        # Probabilidades calculadas\n",
    "\n",
    "    # Recorremos batches del conjunto de validaci√≥n/test\n",
    "    for inputs, _, labels in test_loader:\n",
    "        # Convertimos a tensores en float32 y los movemos a CPU/GPU\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Reiniciamos gradientes (buena pr√°ctica, aunque en eval no se usan)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Desactivamos c√°lculo de gradientes\n",
    "        with torch.set_grad_enabled(False):\n",
    "            # Forward pass\n",
    "            outputs = net(inputs)\n",
    "            loss = 0\n",
    "\n",
    "            # Calculamos BCELoss por cada clase\n",
    "            for i in range(num_classes):\n",
    "                labe = labels.clone()\n",
    "                labe[labels == i] = 1\n",
    "                labe[labels != i] = 0\n",
    "                loss += criterion(F.sigmoid(outputs[:, i].float()), labe.float().to(device))\n",
    "\n",
    "            # Convertimos outputs a numpy para m√©tricas (softmax)\n",
    "            outputs_array = F.softmax(outputs.clone().detach().cpu(), dim=1).numpy()\n",
    "            maps = np.append(maps, outputs_array, axis=0)\n",
    "\n",
    "            labels_array = labels.clone().cpu().detach().numpy()\n",
    "            lab = np.append(lab, labels_array)\n",
    "\n",
    "            # Predicci√≥n de la clase con mayor probabilidad\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Sumamos la p√©rdida y calculamos aciertos\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    # El scheduler ajusta el learning rate si no ha habido mejora\n",
    "    scheduler.step(loss)\n",
    "\n",
    "    # P√©rdida media y accuracy en el conjunto de validaci√≥n/test\n",
    "    epoch_loss = running_loss / len(test_loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(test_loader.dataset)\n",
    "\n",
    "    # C√°lculo de NAP y AUC (micro)\n",
    "    epoch_nap, epoch_f = norm_ap_optimized(maps, lab, num_classes)\n",
    "    epoch_auc = pltauc(maps, lab, num_classes)\n",
    "\n",
    "    # Imprimimos resultados\n",
    "    print('Phase Validation, Loss: {:.4f} Acc: {:.4f} NAP: {:.4f} F-measure: {:.4f} AUC: {:.4f}'.format(\n",
    "        epoch_loss, epoch_acc, epoch_nap[-1], epoch_f[-1], epoch_auc[\"micro\"]))\n",
    "\n",
    "    # predictions se podr√≠a usar para generar informes o visualizaciones\n",
    "    predictions = [maps, lab]\n",
    "    return epoch_loss, epoch_acc, epoch_nap[-1], epoch_f[-1], epoch_auc[\"micro\"], predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Bucle Principal de Entrenamiento\n",
    "\n",
    "Controla el n√∫mero de √©pocas, guarda el mejor modelo seg√∫n la m√©trica (NAP, por ejemplo) y produce gr√°ficas de evoluci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch = 0\n",
    "num_epochs = 30\n",
    "\n",
    "results_dir = './PharmaNet'\n",
    "results_path = 'Best_Config'\n",
    "\n",
    "# Historial para gr√°ficas\n",
    "train_losses_history, val_losses_history = [], []\n",
    "train_acc_history, val_acc_history = [], []\n",
    "train_nap_history, val_nap_history = [], []\n",
    "train_f_history, val_f_history = [], []\n",
    "train_auc_history, val_auc_history = [], []\n",
    "\n",
    "best_model_wts = copy.deepcopy(net.state_dict())\n",
    "saving_path_models = os.path.join(results_dir, results_path, 'model'+str(cross_val)+'/')\n",
    "if not os.path.exists(saving_path_models):\n",
    "    os.makedirs(saving_path_models, 0o777)\n",
    "\n",
    "def main():\n",
    "    since = time.time()\n",
    "    best_NAP = 0\n",
    "    best_prediction = None\n",
    "\n",
    "    for epoch in range(initial_epoch, num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Entrenar\n",
    "        train_loss, train_acc, train_nap, train_f, train_auc = train(epoch)\n",
    "        train_losses_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc)\n",
    "        train_auc_history.append(train_auc)\n",
    "        train_nap_history.append(train_nap)\n",
    "        train_f_history.append(train_f)\n",
    "\n",
    "        # Validar\n",
    "        val_loss, val_acc, val_nap, val_f, val_auc, prediction_nap = evaluate(epoch)\n",
    "        val_losses_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc)\n",
    "        val_auc_history.append(val_auc)\n",
    "        val_nap_history.append(val_nap)\n",
    "        val_f_history.append(val_f)\n",
    "\n",
    "        # Guardar el mejor modelo si la m√©trica (NAP) mejora\n",
    "        if val_nap > best_NAP:\n",
    "            best_NAP = val_nap\n",
    "            best_prediction = prediction_nap\n",
    "            best_model_wts = copy.deepcopy(net.state_dict())\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': train_losses_history\n",
    "            }, os.path.join(saving_path_models, 'Checkpoint.pth'))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val NAP: {:4f}'.format(best_NAP))\n",
    "    print('Best val ACC: {:4f}'.format(max(val_acc_history)))\n",
    "    print('Best val AUC: {:4f}'.format(max(val_auc_history)))\n",
    "    print('Best val Fscore: {:4f}'.format(max(val_f_history)))\n",
    "\n",
    "    net.load_state_dict(best_model_wts)\n",
    "    torch.save({\n",
    "        'model': net.state_dict(),\n",
    "        'optimize': optimizer.state_dict(),\n",
    "        'prediction': best_prediction,\n",
    "        'charset': char_to_int,\n",
    "        'embed': embed\n",
    "    }, os.path.join(saving_path_models, 'model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Ejemplos resultados de Entrenamiento\n",
    "\n",
    "![](PharmaNet/Best_Config/model1/losses_30.png)\n",
    "\n",
    "![](PharmaNet/Best_Config/model1/nap30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Inferencia \n",
    "\n",
    "A continuaci√≥n, un **script simplificado** para cargar el modelo entrenado y procesar un archivo CSV de prueba, generando resultados y m√©tricas finales como NAP, AUC y Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo desde: ./PharmaNet/Best_Config/model1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencia: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42/42 [04:53<00:00,  6.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RESULTADOS DE INFERENCIA]\n",
      "  NAP: 0.5388\n",
      "  AP (micro): 0.6238\n",
      "  AUC (micro): 0.9631\n",
      "  Accuracy: 0.6193\n",
      "\n",
      "{'NAP': 0.5388127902130617, 'AP_micro': 0.623795282687368, 'AUC_micro': 0.9631357541683457, 'Accuracy': 0.6193192622171515}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data.data_loader import SMILESDataset\n",
    "from utils.metrics import pltmap, pltauc, norm_ap\n",
    "from models.Model import Model\n",
    "\n",
    "def inference_example(\n",
    "    data_test,           # DataFrame con SMILES y etiquetas\n",
    "    saving_path_models,  # Ruta donde est√° el modelo entrenado (model.pth)\n",
    "    device,              # \"cuda\" o \"cpu\"\n",
    "    num_classes,         # Cantidad de clases/targets\n",
    "    hidden_size,         # Tama√±o hidden para la red\n",
    "    bidireccional,       # Boolean, si la RNN es bidireccional\n",
    "    num_layers,          # N√∫mero de capas en la RNN\n",
    "    kernel_size,         # Tama√±o kernel para convoluci√≥n\n",
    "    neighbours,          # Par√°metro extra para SMILESDataset\n",
    "    padding,             # Padding usado en SMILESDataset\n",
    "    batch_size,          # Tama√±o de batch para DataLoader\n",
    "    workers              # Num. de workers para DataLoader\n",
    "):\n",
    "    \"\"\"\n",
    "    Ejemplo simplificado de inferencia con PharmaNet.\n",
    "    - data_test: DataFrame con columnas ['Smiles','Label']\n",
    "    - Se asume que 'model.pth' contiene ['model','charset','embed'].\n",
    "    \"\"\"\n",
    "    print(\"Cargando modelo desde:\", saving_path_models)\n",
    "    model_path = os.path.join(saving_path_models, 'model.pth')\n",
    "    trained_model = torch.load(model_path, map_location=device)\n",
    "\n",
    "    # Reconstruir diccionario de caracteres y embed\n",
    "    char_to_int_inf = trained_model['charset']\n",
    "    embed_inf       = trained_model['embed']\n",
    "    vocab_size_inf  = len(char_to_int_inf)\n",
    "\n",
    "    # Reconstruir el modelo con los mismos hiperpar√°metros\n",
    "    model_infer = Model(\n",
    "        vocab_size_inf,\n",
    "        num_classes,\n",
    "        hidden_size,\n",
    "        bidireccional,\n",
    "        num_layers,\n",
    "        kernel_size\n",
    "    ).to(device)\n",
    "\n",
    "    model_infer.load_state_dict(trained_model['model'])\n",
    "    model_infer.eval()\n",
    "\n",
    "    # Crear dataset de prueba (ej: tomar 10 filas para demo)\n",
    "    test_dataset_inf = SMILESDataset(\n",
    "        data_test,    # <-- ajusta seg√∫n tu preferencia\n",
    "        vocab_size_inf,\n",
    "        char_to_int_inf,\n",
    "        embed_inf,\n",
    "        neighbours,\n",
    "        padding\n",
    "    )\n",
    "\n",
    "    test_loader_inf = DataLoader(\n",
    "        test_dataset_inf,\n",
    "        batch_size=batch_size,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        num_workers=workers\n",
    "    )\n",
    "\n",
    "    all_outputs = np.empty((0, num_classes))\n",
    "    all_labels  = np.array([])\n",
    "\n",
    "    # Bucle de inferencia\n",
    "    for inputs, _, labels in tqdm(test_loader_inf, desc=\"Inferencia\"):\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model_infer(inputs)    # (batch_size, num_classes)\n",
    "            out_soft = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "            all_outputs = np.append(all_outputs, out_soft, axis=0)\n",
    "\n",
    "            # Guardamos las etiquetas reales para m√©tricas\n",
    "            labels_np = labels.cpu().numpy()\n",
    "            all_labels = np.append(all_labels, labels_np)\n",
    "\n",
    "    # ===================\n",
    "    # C√°lculo de m√©tricas\n",
    "    # ===================\n",
    "    unique_classes = np.unique(all_labels)\n",
    "\n",
    "    # 1) NAP\n",
    "    epoch_nap, epoch_f = norm_ap(all_outputs, all_labels)\n",
    "\n",
    "    # 2) MAP\n",
    "    epoch_ap, _ = pltmap(all_outputs, all_labels, num_classes)\n",
    "\n",
    "    # 3) AUC (verificamos que haya al menos 2 clases)\n",
    "    if len(unique_classes) < 2:\n",
    "        print(\"Solo hay una clase en los datos. No se puede calcular AUC.\")\n",
    "        epoch_auc = {\"micro\": 0.0, \"macro\": 0.0}\n",
    "    else:\n",
    "        epoch_auc = pltauc(all_outputs, all_labels, num_classes)\n",
    "\n",
    "    # 4) Accuracy\n",
    "    preds = np.argmax(all_outputs, axis=1)\n",
    "    running_corrects = np.sum(preds == all_labels)\n",
    "    epoch_acc = running_corrects / len(all_labels) if len(all_labels) > 0 else 0.0\n",
    "\n",
    "    print(f\"\\n[RESULTADOS DE INFERENCIA]\")\n",
    "    print(f\"  NAP: {epoch_nap[-1]:.4f}\")\n",
    "    print(f\"  AP (micro): {epoch_ap['micro']:.4f}\")\n",
    "    print(f\"  AUC (micro): {epoch_auc['micro']:.4f}\")\n",
    "    print(f\"  Accuracy: {epoch_acc:.4f}\\n\")\n",
    "\n",
    "    return {\n",
    "        \"NAP\": epoch_nap[-1],\n",
    "        \"AP_micro\": epoch_ap[\"micro\"],\n",
    "        \"AUC_micro\": epoch_auc[\"micro\"],\n",
    "        \"Accuracy\": epoch_acc\n",
    "    }\n",
    "\n",
    "# Ejemplo de uso:\n",
    "resultados = inference_example(\n",
    "     data_test=data_test,\n",
    "     saving_path_models=saving_path_models,\n",
    "     device=\"cpu\",\n",
    "     num_classes=num_classes,\n",
    "     hidden_size=hidden_size,\n",
    "     bidireccional=bidireccional,\n",
    "     num_layers=num_layers,\n",
    "     kernel_size=kernel_size,\n",
    "     neighbours=neighbours,\n",
    "     padding=padding,\n",
    "     batch_size=batch_size,\n",
    "     workers=workers\n",
    ")\n",
    "print(resultados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PharmaNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
