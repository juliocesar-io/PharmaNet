{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Banner.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **IA Biomédica:** Laboratorio PharmaNet: Modelo, entrenamiento e inferencia \n",
    "\n",
    "\n",
    "> ##### Descubrimiento de Farmacos\n",
    "\n",
    "\n",
    "> **Instructores**\n",
    "\n",
    "*  Julio Castellanos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Práctica: Análisis y Comprensión de PharmaNet\n",
    "\n",
    "Esta práctica se enfoca en revisar dos scripts fundamentales:\n",
    "\n",
    "- El código de entrenamiento, donde se definen las rutinas para cargar datos, entrenar y evaluar el modelo con métricas como Accuracy, NAP y AUC.\n",
    "- El código de inferencia, que demuestra cómo aplicar el modelo para obtener predicciones con moléculas de test.\n",
    "\n",
    "La meta principal es entender paso a paso cómo funciona PharmaNet al transformar SMILES en tensores, procesarlos mediante su arquitectura (Conv + RNN) y generar probabilidades de afinidad para cada target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PharmaNet Tutorial: Entrenamiento e Inferencia\n",
    "\n",
    "Este *Notebook* ilustra los pasos fundamentales para:\n",
    "1. Entrenar el modelo **PharmaNet** usando datos de SMILES.\n",
    "2. Realizar  inferencia sobre un conjunto de prueba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports Principales para Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliocesar/miniforge3/envs/PharmaNet/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.9.0.post2\n"
     ]
    }
   ],
   "source": [
    "# ## 1. Importaciones Principales\n",
    "\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Modulos propios (asegúrate de tener estas rutas en tu proyecto)\n",
    "from data.data_loader import SMILESDataset\n",
    "from utils.metrics import pltauc, norm_ap_optimized\n",
    "from models.Model import Model\n",
    "\n",
    "\n",
    "print(\"PyTorch Version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuración de Parámetros y Semilla\n",
    "\n",
    "En esta sección, definimos los parámetros necesarios para la ejecución:\n",
    "- GPU o CPU\n",
    "- Fijación de semilla aleatoria para reproducibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo seleccionado: cpu\n"
     ]
    }
   ],
   "source": [
    "# 2. Configuración de Parámetros y Semilla\n",
    "\n",
    "seed = 6766\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Configurar GPU (si está disponible)\n",
    "ngpu = 1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '{}'.format(ngpu)\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "print(\"Dispositivo seleccionado:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lectura de Datos y Cross-Validation\n",
    "\n",
    "Aquí cargamos archivos CSV con SMILES (por ejemplo, `Smiles_1.csv`, `Smiles_2.csv`, etc.) y seleccionamos la parte de entrenamiento y prueba según un índice de `cross_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for train: 15321\n",
      "Data for test : 5259\n"
     ]
    }
   ],
   "source": [
    "# 3. Lectura de Datos\n",
    "train_path = \"data/datasets/DUDE/\"\n",
    "A = pd.read_csv(train_path + 'Smiles_1.csv')\n",
    "B = pd.read_csv(train_path + 'Smiles_2.csv')\n",
    "C = pd.read_csv(train_path + 'Smiles_3.csv')\n",
    "D = pd.read_csv(train_path + 'Smiles_4.csv')\n",
    "\n",
    "cross_val = 1\n",
    "\n",
    "if cross_val == 1:\n",
    "    data_train = pd.concat([A, B, C], ignore_index=True)\n",
    "    data_test = D\n",
    "elif cross_val == 2:\n",
    "    data_train = pd.concat([A, C, D], ignore_index=True)\n",
    "    data_test = B\n",
    "elif cross_val == 3:\n",
    "    data_train = pd.concat([A, B, D], ignore_index=True)\n",
    "    data_test = C\n",
    "else:\n",
    "    data_train = pd.concat([B, C, D], ignore_index=True)\n",
    "    data_test = A\n",
    "\n",
    "print('Data for train:', len(data_train['Smiles']))\n",
    "print('Data for test :', len(data_test['Smiles']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Target</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC[C@H](Cc1cccc(F)c1)NC(=O)c4cc(Br)c(c2ccnc3[n...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cc4n[nH]c5ccc(c3cncc(OC[C@@H](N)Cc1c[nH]c2cccc...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N[C@H](COc4cncc(c3ccc2NC(=O)C(c1ccco1)c2c3)c4)...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(C)(Cc1ccco1)C5C(=O)Nc6ccc(c4cncc(OC[C@@H](N...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCn3c(c1nonc1N)nc4c(C#CC(C)(C)O)nc(O[C@@H](CCN...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15316</th>\n",
       "      <td>COc1ccc(F)cc1C(C)(C)CC(O)(Cc2cc(C)cc(C)c2)C(F)...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15317</th>\n",
       "      <td>OC(=O)c5ccc4C3=NN(c1ccc(C#N)c(Cl)c1)[C@H](c2cc...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15318</th>\n",
       "      <td>COc1ccc(F)cc1C(C)(C)CC(O)(Cc2cc(C)cc(C)c2C#N)C...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15319</th>\n",
       "      <td>COc4c(O)ccc5o\\c(=C/c1cccc(O)c1)c3C2C(NC(C)(C)C...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15320</th>\n",
       "      <td>CC(Cc1c[nH]c2ccccc12)NS(=O)(=O)c3c(C)cc(C)cc3C</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15321 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Smiles Target  Label\n",
       "0      NC[C@H](Cc1cccc(F)c1)NC(=O)c4cc(Br)c(c2ccnc3[n...   akt1      0\n",
       "1      Cc4n[nH]c5ccc(c3cncc(OC[C@@H](N)Cc1c[nH]c2cccc...   akt1      0\n",
       "2      N[C@H](COc4cncc(c3ccc2NC(=O)C(c1ccco1)c2c3)c4)...   akt1      0\n",
       "3      CC(C)(Cc1ccco1)C5C(=O)Nc6ccc(c4cncc(OC[C@@H](N...   akt1      0\n",
       "4      CCn3c(c1nonc1N)nc4c(C#CC(C)(C)O)nc(O[C@@H](CCN...   akt1      0\n",
       "...                                                  ...    ...    ...\n",
       "15316  COc1ccc(F)cc1C(C)(C)CC(O)(Cc2cc(C)cc(C)c2)C(F)...    mcr    101\n",
       "15317  OC(=O)c5ccc4C3=NN(c1ccc(C#N)c(Cl)c1)[C@H](c2cc...    mcr    101\n",
       "15318  COc1ccc(F)cc1C(C)(C)CC(O)(Cc2cc(C)cc(C)c2C#N)C...    mcr    101\n",
       "15319  COc4c(O)ccc5o\\c(=C/c1cccc(O)c1)c3C2C(NC(C)(C)C...    mcr    101\n",
       "15320     CC(Cc1c[nH]c2ccccc12)NS(=O)(=O)c3c(C)cc(C)cc3C    mcr    101\n",
       "\n",
       "[15321 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Target</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C/C(c1ccc[nH]1)=c2/c(=O)[nH]c3ccc(NC(N)=O)cc23</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cc3n[nH]c4cn(=O)c(c2cncc(OC[C@@H](N)Cc1ccccc1)...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C5CN(Cc4ccc(c2nc1ncccc1cc2c3ccccc3)cc4)CCC5c7c...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N[C@H](COc4cncc(c3ccc2cnc(c1ccncc1)cc2c3)c4)Cc...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cc4n[nH]c5ccc(c3cncc(OC[C@@H](N)Cc2cccc(c1cccc...</td>\n",
       "      <td>akt1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>Clc4cccc(C3CCN(c1[nH]c(=O)[nH]c(=O)c1Cc2ccccc2...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>CC1(C)CCC[C@@]4(C)[C@@H]1Nc3cc2nc(O)cc(C(F)(F)...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5256</th>\n",
       "      <td>CC#C[C@]5(O)CC[C@H]4[C@@H]2CCC1=CC(=O)CCC1=C2[...</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>COc1ccc(F)cc1C(C)(C)CC(O)(Cn2cc(C)nc2C)C(F)(F)F</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5258</th>\n",
       "      <td>CC4=CC(C)(C)Nc5ccc3c1cc(F)ccc1oc(=C2SCCCS2)c3c45</td>\n",
       "      <td>mcr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5259 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Smiles Target  Label\n",
       "0        C/C(c1ccc[nH]1)=c2/c(=O)[nH]c3ccc(NC(N)=O)cc23   akt1      0\n",
       "1     Cc3n[nH]c4cn(=O)c(c2cncc(OC[C@@H](N)Cc1ccccc1)...   akt1      0\n",
       "2     C5CN(Cc4ccc(c2nc1ncccc1cc2c3ccccc3)cc4)CCC5c7c...   akt1      0\n",
       "3     N[C@H](COc4cncc(c3ccc2cnc(c1ccncc1)cc2c3)c4)Cc...   akt1      0\n",
       "4     Cc4n[nH]c5ccc(c3cncc(OC[C@@H](N)Cc2cccc(c1cccc...   akt1      0\n",
       "...                                                 ...    ...    ...\n",
       "5254  Clc4cccc(C3CCN(c1[nH]c(=O)[nH]c(=O)c1Cc2ccccc2...    mcr    101\n",
       "5255  CC1(C)CCC[C@@]4(C)[C@@H]1Nc3cc2nc(O)cc(C(F)(F)...    mcr    101\n",
       "5256  CC#C[C@]5(O)CC[C@H]4[C@@H]2CCC1=CC(=O)CCC1=C2[...    mcr    101\n",
       "5257    COc1ccc(F)cc1C(C)(C)CC(O)(Cn2cc(C)nc2C)C(F)(F)F    mcr    101\n",
       "5258   CC4=CC(C)(C)Nc5ccc3c1cc(F)ccc1oc(=C2SCCCS2)c3c45    mcr    101\n",
       "\n",
       "[5259 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparación del Vocabulario (charset) y Definición de Longitud Máxima\n",
    "Extraemos un conjunto de caracteres únicos usados en los SMILES y calculamos la longitud máxima de la secuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteres únicos: {'(', '1', 'o', '#', 'B', 'i', 'r', 'n', ']', '-', 'O', '\\\\', '=', '+', 'c', ')', 'l', 'C', 's', '7', '9', '8', '@', 'N', '5', 'S', 'H', 'P', '2', 'F', '[', '3', '/', 'I', '6', '4'}\n",
      "Total de caracteres: 36\n",
      "Max. longitud de SMILE: 116\n"
     ]
    }
   ],
   "source": [
    "# 4. Vocabulario y Embedding\n",
    "charset = set(\"\".join(list(data_train.Smiles)) + \"\".join(list(data_test.Smiles)))\n",
    "vocab_size = len(charset)\n",
    "char_to_int = dict((c, i) for i, c in enumerate(charset))\n",
    "\n",
    "embed_tr = max([len(smile) for smile in data_train.Smiles])\n",
    "embed_te = max([len(smile) for smile in data_test.Smiles])\n",
    "embed = max(embed_tr, embed_te)\n",
    "\n",
    "print('Caracteres únicos:', str(charset))\n",
    "print('Total de caracteres:', vocab_size)\n",
    "print('Max. longitud de SMILE:', embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Construcción del Modelo (PharmaNet)\n",
    "\n",
    "Se instancia la clase `Model(...)` que define la arquitectura Conv + RNN.  \n",
    "Luego se imprime el modelo para revisar su estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "Model(\n",
      "  (module_mol): ModuleList(\n",
      "    (0): Conv2d(36, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(3, 2))\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): GRU(128, 256, num_layers=10, batch_first=True, bidirectional=True)\n",
      "    (5): Upsample(size=64, mode=nearest)\n",
      "  )\n",
      "  (fc1): Linear(in_features=512, out_features=102, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Construcción del Modelo\n",
    "num_classes = max(data_train.Label) + 1\n",
    "print(num_classes)\n",
    "hidden_size = 256\n",
    "kernel_size = 5\n",
    "\n",
    "bidireccional = True\n",
    "num_layers = 10\n",
    "\n",
    "net = Model(vocab_size,\n",
    "            num_classes,\n",
    "            hidden_size,\n",
    "            bidireccional,\n",
    "            num_layers,\n",
    "            kernel_size\n",
    "            ).to(device)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Definición del Optimizador y la Función de Pérdida\n",
    "\n",
    "Usamos Adam como optimizador y BCELoss (aplicando `sigmoid` en cada clase).  \n",
    "El scheduler reduce el learning rate si no hay mejoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Optimizador y Pérdida\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=7)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Creación de los DataLoaders (Train/Test)\n",
    "\n",
    "Se definen:\n",
    "- El dataset con la clase `SMILESDataset`.\n",
    "- DataLoader con sampler balanceado o shuffle, según los argumentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader y test loader creados.\n"
     ]
    }
   ],
   "source": [
    "# 7. DataLoaders\n",
    "\n",
    "neighbours = 0\n",
    "padding = False\n",
    "\n",
    "batch_size = 128\n",
    "workers = 4\n",
    "\n",
    "train_datasets = SMILESDataset(data_train, vocab_size, char_to_int, embed, neighbours, padding)\n",
    "test_datasets  = SMILESDataset(data_test, vocab_size, char_to_int, embed, neighbours, padding)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_datasets, batch_size=batch_size, drop_last=True, shuffle=True, num_workers=workers)\n",
    "test_loader  = DataLoader(test_datasets,  batch_size=batch_size, drop_last=True, shuffle=True, num_workers=workers)\n",
    "\n",
    "print(\"Train loader y test loader creados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Funciones de Entrenamiento y Evaluación\n",
    "\n",
    "- **train(epoch)**: Modo `train()`, calcula pérdida y backprop.\n",
    "- **evaluate(epoch)**: Modo `eval()`, sin backprop, y se calculan métricas finales (NAP, AUC, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    # Coloca el modelo en modo entrenamiento (permite dropout, actualiza gradientes)\n",
    "    net.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    lab = np.array([])                       # Para almacenar etiquetas reales\n",
    "    maps = np.empty((0, num_classes))        # Para almacenar predicciones (probabilidades)\n",
    "\n",
    "    # Iteramos sobre cada batch (inputs, _, labels) proveniente de train_loader\n",
    "    for inputs, _, labels in tqdm(train_loader):\n",
    "        # Convertimos a tensores en float32 y los movemos al dispositivo (CPU/GPU)\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Reiniciamos gradientes antes de cada batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Activamos el cálculo de gradientes\n",
    "        with torch.set_grad_enabled(True):\n",
    "            # Forward pass: obtenemos outputs de la red\n",
    "            outputs = net(inputs)\n",
    "            loss = 0\n",
    "\n",
    "            # Para cada clase, calculamos el aporte a la pérdida usando BCELoss\n",
    "            for i in range(num_classes):\n",
    "                labe = labels.clone()\n",
    "                labe[labels == i] = 1\n",
    "                labe[labels != i] = 0\n",
    "                loss += criterion(F.sigmoid(outputs[:, i].float()), labe.float().to(device))\n",
    "\n",
    "            # Convertimos outputs a numpy para calcular métricas (softmax de outputs)\n",
    "            outputs_array = F.softmax(outputs.clone().detach().cpu(), dim=1).numpy()\n",
    "            maps = np.append(maps, outputs_array, axis=0)\n",
    "\n",
    "            # Guardamos las etiquetas en un array para métricas\n",
    "            labels_array = labels.clone().cpu().detach().numpy()\n",
    "            lab = np.append(lab, labels_array)\n",
    "\n",
    "            # Obtenemos la predicción (clase con mayor probabilidad)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Backprop: calculamos gradientes y actualizamos pesos\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Acumulamos pérdida total del batch\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Calculamos aciertos para accuracy\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    # Pérdida media en la época\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    # Precisión en la época\n",
    "    epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "    # Cálculo de métricas: NAP y AUC (incluye macro y micro)\n",
    "    epoch_nap, epoch_f = norm_ap_optimized(maps, lab, num_classes)\n",
    "    epoch_auc = pltauc(maps, lab, num_classes)\n",
    "\n",
    "    # Imprimimos métricas clave\n",
    "    print('Phase Train, Loss: {:.4f} Acc: {:.4f} NAP: {:.4f} F-measure: {:.4f} AUC: {:.4f}'.format(\n",
    "        epoch_loss, epoch_acc, epoch_nap[-1], epoch_f[-1], epoch_auc[\"micro\"]))\n",
    "\n",
    "    # Retornamos valores relevantes para graficar o almacenar\n",
    "    return epoch_loss, epoch_acc, epoch_nap[-1], epoch_f[-1], epoch_auc[\"micro\"]\n",
    "\n",
    "\n",
    "def evaluate(epoch):\n",
    "    # Coloca el modelo en modo evaluación (desactiva dropout, no requiere gradientes)\n",
    "    net.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    lab = np.array([])                       # Etiquetas reales\n",
    "    maps = np.empty((0, num_classes))        # Probabilidades calculadas\n",
    "\n",
    "    # Recorremos batches del conjunto de validación/test\n",
    "    for inputs, _, labels in test_loader:\n",
    "        # Convertimos a tensores en float32 y los movemos a CPU/GPU\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Reiniciamos gradientes (buena práctica, aunque en eval no se usan)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Desactivamos cálculo de gradientes\n",
    "        with torch.set_grad_enabled(False):\n",
    "            # Forward pass\n",
    "            outputs = net(inputs)\n",
    "            loss = 0\n",
    "\n",
    "            # Calculamos BCELoss por cada clase\n",
    "            for i in range(num_classes):\n",
    "                labe = labels.clone()\n",
    "                labe[labels == i] = 1\n",
    "                labe[labels != i] = 0\n",
    "                loss += criterion(F.sigmoid(outputs[:, i].float()), labe.float().to(device))\n",
    "\n",
    "            # Convertimos outputs a numpy para métricas (softmax)\n",
    "            outputs_array = F.softmax(outputs.clone().detach().cpu(), dim=1).numpy()\n",
    "            maps = np.append(maps, outputs_array, axis=0)\n",
    "\n",
    "            labels_array = labels.clone().cpu().detach().numpy()\n",
    "            lab = np.append(lab, labels_array)\n",
    "\n",
    "            # Predicción de la clase con mayor probabilidad\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Sumamos la pérdida y calculamos aciertos\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    # El scheduler ajusta el learning rate si no ha habido mejora\n",
    "    scheduler.step(loss)\n",
    "\n",
    "    # Pérdida media y accuracy en el conjunto de validación/test\n",
    "    epoch_loss = running_loss / len(test_loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(test_loader.dataset)\n",
    "\n",
    "    # Cálculo de NAP y AUC (micro)\n",
    "    epoch_nap, epoch_f = norm_ap_optimized(maps, lab, num_classes)\n",
    "    epoch_auc = pltauc(maps, lab, num_classes)\n",
    "\n",
    "    # Imprimimos resultados\n",
    "    print('Phase Validation, Loss: {:.4f} Acc: {:.4f} NAP: {:.4f} F-measure: {:.4f} AUC: {:.4f}'.format(\n",
    "        epoch_loss, epoch_acc, epoch_nap[-1], epoch_f[-1], epoch_auc[\"micro\"]))\n",
    "\n",
    "    # predictions se podría usar para generar informes o visualizaciones\n",
    "    predictions = [maps, lab]\n",
    "    return epoch_loss, epoch_acc, epoch_nap[-1], epoch_f[-1], epoch_auc[\"micro\"], predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Bucle Principal de Entrenamiento\n",
    "\n",
    "Controla el número de épocas, guarda el mejor modelo según la métrica (NAP, por ejemplo) y produce gráficas de evolución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch = 0\n",
    "num_epochs = 30\n",
    "\n",
    "results_dir = './PharmaNet'\n",
    "results_path = 'Best_Config'\n",
    "\n",
    "# Historial para gráficas\n",
    "train_losses_history, val_losses_history = [], []\n",
    "train_acc_history, val_acc_history = [], []\n",
    "train_nap_history, val_nap_history = [], []\n",
    "train_f_history, val_f_history = [], []\n",
    "train_auc_history, val_auc_history = [], []\n",
    "\n",
    "best_model_wts = copy.deepcopy(net.state_dict())\n",
    "saving_path_models = os.path.join(results_dir, results_path, 'model'+str(cross_val)+'/')\n",
    "if not os.path.exists(saving_path_models):\n",
    "    os.makedirs(saving_path_models, 0o777)\n",
    "\n",
    "def main():\n",
    "    since = time.time()\n",
    "    best_NAP = 0\n",
    "    best_prediction = None\n",
    "\n",
    "    for epoch in range(initial_epoch, num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Entrenar\n",
    "        train_loss, train_acc, train_nap, train_f, train_auc = train(epoch)\n",
    "        train_losses_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc)\n",
    "        train_auc_history.append(train_auc)\n",
    "        train_nap_history.append(train_nap)\n",
    "        train_f_history.append(train_f)\n",
    "\n",
    "        # Validar\n",
    "        val_loss, val_acc, val_nap, val_f, val_auc, prediction_nap = evaluate(epoch)\n",
    "        val_losses_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc)\n",
    "        val_auc_history.append(val_auc)\n",
    "        val_nap_history.append(val_nap)\n",
    "        val_f_history.append(val_f)\n",
    "\n",
    "        # Guardar el mejor modelo si la métrica (NAP) mejora\n",
    "        if val_nap > best_NAP:\n",
    "            best_NAP = val_nap\n",
    "            best_prediction = prediction_nap\n",
    "            best_model_wts = copy.deepcopy(net.state_dict())\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': train_losses_history\n",
    "            }, os.path.join(saving_path_models, 'Checkpoint.pth'))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val NAP: {:4f}'.format(best_NAP))\n",
    "    print('Best val ACC: {:4f}'.format(max(val_acc_history)))\n",
    "    print('Best val AUC: {:4f}'.format(max(val_auc_history)))\n",
    "    print('Best val Fscore: {:4f}'.format(max(val_f_history)))\n",
    "\n",
    "    net.load_state_dict(best_model_wts)\n",
    "    torch.save({\n",
    "        'model': net.state_dict(),\n",
    "        'optimize': optimizer.state_dict(),\n",
    "        'prediction': best_prediction,\n",
    "        'charset': char_to_int,\n",
    "        'embed': embed\n",
    "    }, os.path.join(saving_path_models, 'model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Ejemplos resultados de Entrenamiento\n",
    "\n",
    "![](PharmaNet/Best_Config/model1/losses_30.png)\n",
    "\n",
    "![](PharmaNet/Best_Config/model1/nap30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Inferencia \n",
    "\n",
    "A continuación, un **script simplificado** para cargar el modelo entrenado y procesar un archivo CSV de prueba, generando resultados y métricas finales como NAP, AUC y Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo desde: ./PharmaNet/Best_Config/model1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencia: 100%|██████████| 42/42 [04:53<00:00,  6.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RESULTADOS DE INFERENCIA]\n",
      "  NAP: 0.5388\n",
      "  AP (micro): 0.6238\n",
      "  AUC (micro): 0.9631\n",
      "  Accuracy: 0.6193\n",
      "\n",
      "{'NAP': 0.5388127902130617, 'AP_micro': 0.623795282687368, 'AUC_micro': 0.9631357541683457, 'Accuracy': 0.6193192622171515}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data.data_loader import SMILESDataset\n",
    "from utils.metrics import pltmap, pltauc, norm_ap\n",
    "from models.Model import Model\n",
    "\n",
    "def inference_example(\n",
    "    data_test,           # DataFrame con SMILES y etiquetas\n",
    "    saving_path_models,  # Ruta donde está el modelo entrenado (model.pth)\n",
    "    device,              # \"cuda\" o \"cpu\"\n",
    "    num_classes,         # Cantidad de clases/targets\n",
    "    hidden_size,         # Tamaño hidden para la red\n",
    "    bidireccional,       # Boolean, si la RNN es bidireccional\n",
    "    num_layers,          # Número de capas en la RNN\n",
    "    kernel_size,         # Tamaño kernel para convolución\n",
    "    neighbours,          # Parámetro extra para SMILESDataset\n",
    "    padding,             # Padding usado en SMILESDataset\n",
    "    batch_size,          # Tamaño de batch para DataLoader\n",
    "    workers              # Num. de workers para DataLoader\n",
    "):\n",
    "    \"\"\"\n",
    "    Ejemplo simplificado de inferencia con PharmaNet.\n",
    "    - data_test: DataFrame con columnas ['Smiles','Label']\n",
    "    - Se asume que 'model.pth' contiene ['model','charset','embed'].\n",
    "    \"\"\"\n",
    "    print(\"Cargando modelo desde:\", saving_path_models)\n",
    "    model_path = os.path.join(saving_path_models, 'model.pth')\n",
    "    trained_model = torch.load(model_path, map_location=device)\n",
    "\n",
    "    # Reconstruir diccionario de caracteres y embed\n",
    "    char_to_int_inf = trained_model['charset']\n",
    "    embed_inf       = trained_model['embed']\n",
    "    vocab_size_inf  = len(char_to_int_inf)\n",
    "\n",
    "    # Reconstruir el modelo con los mismos hiperparámetros\n",
    "    model_infer = Model(\n",
    "        vocab_size_inf,\n",
    "        num_classes,\n",
    "        hidden_size,\n",
    "        bidireccional,\n",
    "        num_layers,\n",
    "        kernel_size\n",
    "    ).to(device)\n",
    "\n",
    "    model_infer.load_state_dict(trained_model['model'])\n",
    "    model_infer.eval()\n",
    "\n",
    "    # Crear dataset de prueba (ej: tomar 10 filas para demo)\n",
    "    test_dataset_inf = SMILESDataset(\n",
    "        data_test,    # <-- ajusta según tu preferencia\n",
    "        vocab_size_inf,\n",
    "        char_to_int_inf,\n",
    "        embed_inf,\n",
    "        neighbours,\n",
    "        padding\n",
    "    )\n",
    "\n",
    "    test_loader_inf = DataLoader(\n",
    "        test_dataset_inf,\n",
    "        batch_size=batch_size,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        num_workers=workers\n",
    "    )\n",
    "\n",
    "    all_outputs = np.empty((0, num_classes))\n",
    "    all_labels  = np.array([])\n",
    "\n",
    "    # Bucle de inferencia\n",
    "    for inputs, _, labels in tqdm(test_loader_inf, desc=\"Inferencia\"):\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model_infer(inputs)    # (batch_size, num_classes)\n",
    "            out_soft = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "            all_outputs = np.append(all_outputs, out_soft, axis=0)\n",
    "\n",
    "            # Guardamos las etiquetas reales para métricas\n",
    "            labels_np = labels.cpu().numpy()\n",
    "            all_labels = np.append(all_labels, labels_np)\n",
    "\n",
    "    # ===================\n",
    "    # Cálculo de métricas\n",
    "    # ===================\n",
    "    unique_classes = np.unique(all_labels)\n",
    "\n",
    "    # 1) NAP\n",
    "    epoch_nap, epoch_f = norm_ap(all_outputs, all_labels)\n",
    "\n",
    "    # 2) MAP\n",
    "    epoch_ap, _ = pltmap(all_outputs, all_labels, num_classes)\n",
    "\n",
    "    # 3) AUC (verificamos que haya al menos 2 clases)\n",
    "    if len(unique_classes) < 2:\n",
    "        print(\"Solo hay una clase en los datos. No se puede calcular AUC.\")\n",
    "        epoch_auc = {\"micro\": 0.0, \"macro\": 0.0}\n",
    "    else:\n",
    "        epoch_auc = pltauc(all_outputs, all_labels, num_classes)\n",
    "\n",
    "    # 4) Accuracy\n",
    "    preds = np.argmax(all_outputs, axis=1)\n",
    "    running_corrects = np.sum(preds == all_labels)\n",
    "    epoch_acc = running_corrects / len(all_labels) if len(all_labels) > 0 else 0.0\n",
    "\n",
    "    print(f\"\\n[RESULTADOS DE INFERENCIA]\")\n",
    "    print(f\"  NAP: {epoch_nap[-1]:.4f}\")\n",
    "    print(f\"  AP (micro): {epoch_ap['micro']:.4f}\")\n",
    "    print(f\"  AUC (micro): {epoch_auc['micro']:.4f}\")\n",
    "    print(f\"  Accuracy: {epoch_acc:.4f}\\n\")\n",
    "\n",
    "    return {\n",
    "        \"NAP\": epoch_nap[-1],\n",
    "        \"AP_micro\": epoch_ap[\"micro\"],\n",
    "        \"AUC_micro\": epoch_auc[\"micro\"],\n",
    "        \"Accuracy\": epoch_acc\n",
    "    }\n",
    "\n",
    "# Ejemplo de uso:\n",
    "resultados = inference_example(\n",
    "     data_test=data_test,\n",
    "     saving_path_models=saving_path_models,\n",
    "     device=\"cpu\",\n",
    "     num_classes=num_classes,\n",
    "     hidden_size=hidden_size,\n",
    "     bidireccional=bidireccional,\n",
    "     num_layers=num_layers,\n",
    "     kernel_size=kernel_size,\n",
    "     neighbours=neighbours,\n",
    "     padding=padding,\n",
    "     batch_size=batch_size,\n",
    "     workers=workers\n",
    ")\n",
    "print(resultados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PharmaNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
